{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = '../data/old'\n",
    "\n",
    "# Get all CSV files in the raw folder\n",
    "all_files = glob.glob(os.path.join(data_directory+'/raw', 'raw_*.csv'))\n",
    "# Read and concatenate all files\n",
    "df_raw = pd.concat((pd.read_csv(f) for f in all_files[:-3]), ignore_index=True)\n",
    "# Create a new session_id column using integer division\n",
    "df_raw['session_id'] = df_raw.index // 256 + 1\n",
    "# Reset timestamp to go from 1-256 and reset back to 1 for each session\n",
    "df_raw['timestamp'] = df_raw.groupby('session_id').cumcount() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_val = pd.concat((pd.read_csv(f) for f in all_files[-3:]), ignore_index=True)\n",
    "df_raw_val['session_id'] = df_raw_val.index // 256 + 1\n",
    "df_raw_val['timestamp'] = df_raw_val.groupby('session_id').cumcount() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_raw.drop(columns=['participantName', 'Signal_Quality', 'timestamp'])\n",
    "data_val = df_raw_val.drop(columns=['participantName', 'Signal_Quality', 'timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 5279/5279 [00:00<00:00, 6075.28it/s]\n",
      "Extracting features: 100%|██████████| 585/585 [00:00<00:00, 7251.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "\n",
    "def perform_fft_features(signal, sampling_rate=256):\n",
    "    \"\"\"Computes four frequency domain features: dominant frequency, average frequency, total energy, and average energy.\"\"\"\n",
    "    n = len(signal)\n",
    "    fft_result = np.fft.fft(signal)  # Compute FFT\n",
    "    freqs = np.fft.fftfreq(n, d=1/sampling_rate)[:n//2]  # Only positive frequencies\n",
    "    magnitudes = np.abs(fft_result)[:n//2]  # Magnitude spectrum\n",
    "\n",
    "    dominant_freq = freqs[np.argmax(magnitudes)]  # Peak frequency\n",
    "    avg_freq = np.sum(freqs * magnitudes) / np.sum(magnitudes)  # Weighted mean frequency\n",
    "    total_energy = np.sum(magnitudes ** 2)  # Total power\n",
    "    avg_energy = total_energy / n  # Normalized energy per sample\n",
    "\n",
    "    return dominant_freq, avg_freq, total_energy, avg_energy\n",
    "\n",
    "def process_session(session_data):\n",
    "    \"\"\"Process a single session of data to extract features.\"\"\"\n",
    "    session_id = session_data['session_id'].iloc[0]\n",
    "    features = {\"session_id\": session_id, 'frequency': session_data['frequency'].iloc[0]}\n",
    "    \n",
    "    # Compute features for each of the 8 signal columns\n",
    "    for col in session_data.columns:\n",
    "        if col != \"session_id\" and col != 'frequency':\n",
    "            dominant_freq, avg_freq, total_energy, avg_energy = perform_fft_features(session_data[col].values)\n",
    "            \n",
    "            features[f\"{col}_dominant_freq\"] = dominant_freq\n",
    "            features[f\"{col}_avg_freq\"] = avg_freq\n",
    "            features[f\"{col}_total_energy\"] = total_energy\n",
    "            features[f\"{col}_avg_energy\"] = avg_energy\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_features(df):\n",
    "    \"\"\"Transforms 256-row sessions into 1-row feature vectors for each session.\"\"\"\n",
    "    # Split data into groups by session_id\n",
    "    grouped_data = [group for _, group in df.groupby(\"session_id\")]\n",
    "    \n",
    "    # Create a pool of workers\n",
    "    with Pool(processes=cpu_count()) as pool:\n",
    "        # Map the process_session function to all groups in parallel\n",
    "        feature_list = list(tqdm(pool.imap(process_session, grouped_data), total=len(grouped_data), desc='Extracting features'))\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    return pd.DataFrame(feature_list)\n",
    "\n",
    "# Extract features from the training data\n",
    "df_train = extract_features(data)\n",
    "\n",
    "# Extract features from the validation data\n",
    "df_val = extract_features(data_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (4223, 32)\n",
      "Testing set shape: (1056, 32)\n",
      "Validation set shape: (585, 32)\n"
     ]
    }
   ],
   "source": [
    "# Split features based on frequency column (labels)\n",
    "X = df_train.drop(['frequency', 'session_id'], axis=1)\n",
    "y = df_train['frequency']\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Prepare validation data\n",
    "X_val = df_val.drop(['frequency', 'session_id'], axis=1)\n",
    "y_val = df_val['frequency']\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the data\n",
    "with open('../data/pickles/fft_data.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_train': X_train,\n",
    "        'X_test': X_test,\n",
    "        'X_val': X_val,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'y_val': y_val\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1057084, 32)\n",
      "Testing set shape: (264271, 32)\n",
      "Validation set shape: (148620, 32)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the data back\n",
    "with open('../data/pickles/fft_data.pkl', 'rb') as f:\n",
    "    dat = pickle.load(f)\n",
    "    \n",
    "X_train = dat['X_train']\n",
    "X_test = dat['X_test']\n",
    "X_val = dat['X_val']\n",
    "y_train = dat['y_train']\n",
    "y_test = dat['y_test']\n",
    "y_val = dat['y_val']\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Performance:\n",
      "Accuracy: 0.6382575757575758\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          10       0.71      0.80      0.75       265\n",
      "          12       0.58      0.57      0.58       256\n",
      "          15       0.59      0.54      0.56       267\n",
      "          20       0.65      0.64      0.65       268\n",
      "\n",
      "    accuracy                           0.64      1056\n",
      "   macro avg       0.63      0.64      0.63      1056\n",
      "weighted avg       0.63      0.64      0.64      1056\n",
      "\n",
      "\n",
      "Validation Set Performance:\n",
      "Accuracy: 0.28717948717948716\n",
      "\n",
      "Validation Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          10       0.26      0.36      0.30       146\n",
      "          12       0.27      0.20      0.23       145\n",
      "          15       0.23      0.18      0.20       147\n",
      "          20       0.37      0.41      0.39       147\n",
      "\n",
      "    accuracy                           0.29       585\n",
      "   macro avg       0.28      0.29      0.28       585\n",
      "weighted avg       0.28      0.29      0.28       585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred_test = rf_model.predict(X_test)\n",
    "\n",
    "# Make predictions on validation set\n",
    "y_pred_val = rf_model.predict(X_val)\n",
    "\n",
    "# Print results\n",
    "print(\"Test Set Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"\\nTest Set Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "print(\"\\nValidation Set Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred_val))\n",
    "print(\"\\nValidation Set Classification Report:\")\n",
    "print(classification_report(y_val, y_pred_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
